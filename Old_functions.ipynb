{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_predictTimeSeriesNew(file_path, sliding_window=1, threshold=0.1, asPercentile=True, percentile=75.0, gamma='scale', kernel='rbf', epsilon=0.1, C=1.0):\n",
    "    \"\"\"\n",
    "    This function reads in csv's in the given path and processes each of them, based on the sliding window.\n",
    "    Creates a Support Vector Regression Model and fits 80% of the data and predicts 20% of the data\n",
    "    \n",
    "    file_path - path to the csv files\n",
    "    sliding_window - how many previous entries should be considered as inputs to the current entry\n",
    "    \n",
    "    return - dictionary of precision, recall and F1-scores for each csv file\n",
    "    \"\"\"\n",
    "\n",
    "    dict = {}\n",
    "    a3_csv = glob.glob(file_path, recursive=True)\n",
    "    for index,file in enumerate(a3_csv):\n",
    "\n",
    "        fname = file.split(\"/\")[4].replace('\\\\','').split(\".\")[0]\n",
    "        \n",
    "        if(not(fname == 'A3Benchmark_all' or fname == 'A4Benchmark_all')):\n",
    "        \n",
    "            #print(\"File name {}\".format(fname))\n",
    "        \n",
    "            # Read in 1 csv file\n",
    "            yahoo_df = pd.read_csv(file)\n",
    "\n",
    "\n",
    "            # these csv files have 9 attributes, but we need only \n",
    "            yahoo_df = yahoo_df[['timestamps','value','anomaly']]\n",
    "\n",
    "            # Extract column names\n",
    "            columnNames = list(yahoo_df.columns)\n",
    "\n",
    "            # Make a copy of the dataframe, one will be used as output, and the other as input\n",
    "            yahoo_df_copy = yahoo_df.copy(deep=True)\n",
    "\n",
    "            # first append a NaN row to the dataframe, because the last row will be lost when shifted\n",
    "            yahoo_df_copy = yahoo_df_copy.append(pd.Series(), ignore_index=True)\n",
    "            yahoo_df_copy = yahoo_df_copy.shift(1)\n",
    "\n",
    "        #     print(\"Copy head\")\n",
    "        #     print(yahoo_df_copy.head(5))\n",
    "\n",
    "            # a NaN row is required to be able to merge\n",
    "            yahoo_df = yahoo_df.append(pd.Series(), ignore_index=True)\n",
    "\n",
    "        #     print(\"Original head\")\n",
    "        #     print(yahoo_df.head(5))\n",
    "\n",
    "            yahoo_df = yahoo_df.rename(columns=createColumnDict(columnNames))\n",
    "\n",
    "            yahoo_merged = yahoo_df_copy.merge(yahoo_df, left_index=True, right_index=True)\n",
    "\n",
    "        #     print(\"Merged head\")\n",
    "        #     print(yahoo_merged.head(5))\n",
    "\n",
    "        #     print(\"Merged tail\")\n",
    "        #     print(yahoo_merged.tail(5))\n",
    "\n",
    "        #     print(yahoo_merged.shape)\n",
    "        #     print(yahoo_merged.head(0))\n",
    "\n",
    "            # TODO put this in a for loop for sliding_window > 1\n",
    "            last_index = yahoo_merged.shape[0] - 1\n",
    "            # drop the 1st and last rows, because they contain NaN values\n",
    "            yahoo_merged = yahoo_merged.drop([0,last_index])\n",
    "\n",
    "    #         yahoo_merged = yahoo_merged.drop(['is_anomaly','is_anomaly_y','timestamp', 'timestamp_y'], axis=1)\n",
    "            train_size = int(len(yahoo_merged) * 0.8)\n",
    "            train_set, test_set = yahoo_merged[:train_size], yahoo_merged[train_size:]\n",
    "            #seperate into features and target\n",
    "            X_train = train_set[['value']]\n",
    "            y_train = train_set[['value_y']]\n",
    "            X_test = test_set[['value']]\n",
    "            y_test = test_set[['value_y']]\n",
    "\n",
    "            # outlier_y column is not needed for forecasting, but needed later to detect outliers\n",
    "            outlier_df = test_set[['anomaly_y']]\n",
    "\n",
    "            svm_clf = SVR(kernel=kernel, gamma=gamma, C=C, epsilon=epsilon)\n",
    "            svm_clf.fit(X_train, np.ravel(y_train))\n",
    "            y_predict = svm_clf.predict(X_test)\n",
    "    #         y_predict1 = y_predict.reshape(-1,1)\n",
    "\n",
    "    #         print(\"Actual anomaly : \")\n",
    "    #         print(outlier_df)\n",
    "\n",
    "            predicted_anomaly = None\n",
    "            if(asPercentile):\n",
    "                predicted_anomaly = get_anomaly_labels_by_deviation_pctile_threshold(np.ravel(y_test), np.ravel(y_predict), percentile) \n",
    "            else:\n",
    "                predicted_anomaly = get_anomaly_labels_by_deviation_threshold(np.ravel(y_test), np.ravel(y_predict), threshold)\n",
    "\n",
    "            metrics = precision_recall_fscore_support(np.ravel(outlier_df), predicted_anomaly, average='binary', zero_division=0)\n",
    "\n",
    "            dict[fname] = [metrics[0], metrics[1], metrics[2]]\n",
    "\n",
    "    return dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_median_table(p1, p2, p3, r1, r2, r3, f1, f2, f3, p1_n, p2_n, p3_n, r1_n, r2_n, r3_n, f1_n, f2_n, f3_n):\n",
    "    \"\"\"\n",
    "    Generates 2 tables which includes the median of precision, recall and f1-score results\n",
    "    First 9 lists belong in 1 table and the other 9 lists belong the other table\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    l1 = [['precision', statistics.median(p1), statistics.median(p2), statistics.median(p3)],\n",
    "          ['recall', statistics.median(r1), statistics.median(r2), statistics.median(r3)],\n",
    "          ['f1-score', statistics.median(f1), statistics.median(f2), statistics.median(f3)]]\n",
    "    table1 = tabulate(l1, headers=['', 'C=1', 'C=25', 'C=50' ], tablefmt='orgtbl')\n",
    "    print()\n",
    "    print('Median when SVR has epsilon=\"0.1\"\\n')\n",
    "    print(table1)\n",
    "    \n",
    "    l2 = [['precision', statistics.median(p1_n), statistics.median(p2_n), statistics.median(p3_n)],\n",
    "          ['recall', statistics.median(r1_n), statistics.median(r2_n), statistics.median(r3_n)],\n",
    "          ['f1-score', statistics.median(f1_n), statistics.median(f2_n), statistics.median(f3_n)]]\n",
    "    table2 = tabulate(l2, headers=['', 'C=1', 'C=25', 'C=50' ], tablefmt='orgtbl')\n",
    "    print()\n",
    "    print('Median when SVR has epsilon=\"0.5\"\\n')\n",
    "    print(table2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_box_plots(p1, p2, p3, r1, r2, r3, f1, f2, f3, p1_n, p2_n, p3_n, r1_n, r2_n, r3_n, f1_n, f2_n, f3_n):\n",
    "\n",
    "    \"\"\"\n",
    "    Takes in 18 lists (6 precision results lists, 6 recall results lists, 6 f1-score results lists) and plots\n",
    "    6 boxplots, each having 3 box plots\n",
    "    \"\"\"\n",
    "    \n",
    "    precision_data = [p1, p2, p3] \n",
    "    recall_data = [r1, r2, r3] \n",
    "    f1_data = [f1, f2, f3] \n",
    "\n",
    "    new_precision_data = [p1_n, p2_n, p3_n]\n",
    "    new_recall_data = [r1_n, r2_n, r3_n]\n",
    "    new_f1_data = [f1_n, f2_n, f3_n]\n",
    "\n",
    "    fig, ax = plt.subplots(3, 2, figsize=(10, 10))\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.7)\n",
    "\n",
    "    ax[0][0].set_title('SVR when epsilon=\"0.1\"')\n",
    "    ax[0][0].set_xlabel('C')\n",
    "    ax[0][0].set_ylabel('Precision')\n",
    "    ax[0][0].set_xticklabels([1,25,50])\n",
    "    ax[0][0].boxplot(precision_data)\n",
    "\n",
    "    ax[0][1].set_title('SVR when epsilon=\"0.5\"')\n",
    "    ax[0][1].set_xlabel('C')\n",
    "    ax[0][1].set_ylabel('Precision')\n",
    "    ax[0][1].set_xticklabels([1,25,50])\n",
    "    ax[0][1].sharey(ax[0, 0])\n",
    "    ax[0][1].boxplot(new_precision_data)\n",
    "\n",
    "    ax[1][0].set_xlabel('C')\n",
    "    ax[1][0].set_ylabel('Recall')\n",
    "    ax[1][0].set_xticklabels([1,25,50])\n",
    "    ax[1][0].boxplot(recall_data)\n",
    "    \n",
    "    ax[1][1].set_xlabel('C')\n",
    "    ax[1][1].set_ylabel('Recall')\n",
    "    ax[1][1].set_xticklabels([1,25,50])\n",
    "    ax[1][1].sharey(ax[1, 0])\n",
    "    ax[1][1].boxplot(new_recall_data)\n",
    "\n",
    "    ax[2][0].set_xlabel('C')\n",
    "    ax[2][0].set_ylabel('F1-score')\n",
    "    ax[2][0].set_xticklabels([1,25,50]) \n",
    "    ax[2][0].boxplot(f1_data)\n",
    "    \n",
    "    ax[2][1].set_xlabel('C')\n",
    "    ax[2][1].set_ylabel('F1-score')\n",
    "    ax[2][1].set_xticklabels([1,25,50]) \n",
    "    ax[2][1].sharey(ax[2, 0])\n",
    "    ax[2][1].boxplot(new_f1_data)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetricResults(dictionary):\n",
    "    \"\"\"\n",
    "    Reads data from the dictionary and generates 3 lists of precision, recall and f1-scores\n",
    "    \n",
    "    dictionary - dictionary containing key, value pairs of filename and metric list\n",
    "    \n",
    "    returns 3 lists of each metric values\n",
    "    \"\"\"\n",
    "\n",
    "    precision_results = []\n",
    "    recall_results = []\n",
    "    f1_results = []\n",
    "    for fname in dictionary:\n",
    "        all_results = dictionary[fname]\n",
    "        precision_results.append(all_results[0])\n",
    "        recall_results.append(all_results[1])\n",
    "        f1_results.append(all_results[2])\n",
    "    \n",
    "    return precision_results, recall_results, f1_results\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
